{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719d7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.yolo import Model\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c68cc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9c68cc7",
    "outputId": "bc5ac329-02a8-42d6-c599-589b8c8e8b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Specify random seed for repeatable results\n",
    "torch.manual_seed(191009)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa0c68f",
   "metadata": {
    "id": "aaa0c68f"
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':4.2f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {avg' + self.fmt + '}'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def accuracy(output, target):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = 1\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        xx = torch.logical_xor(pred.view(pred.shape[1]), target)\n",
    "        fn = sum(torch.logical_and(xx, target))\n",
    "        fp = sum(xx) - fn\n",
    "\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        correct_k = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
    "        return correct_k.mul_(100.0 / batch_size), fn * 100.0 / 16, fp * 100.0 / 16\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter('Eval_Acc', ':4.2f')\n",
    "    fpr = AverageMeter('Eval_FPR', ':4.2f')\n",
    "    fnr = AverageMeter('EVAL_FPR', ':4.2f')\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            cnt += 1\n",
    "            acc1, fn, fp = accuracy(output, target)\n",
    "#             print('.', end = '')\n",
    "            top1.update(acc1[0], image.size(0))\n",
    "            fpr.update(fp)\n",
    "            fnr.update(fn)\n",
    "\n",
    "    return top1, fpr, fnr\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7db321",
   "metadata": {
    "id": "aa7db321"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class to load from self-defined dir-structure\n",
    "class ZeroOneSet(Dataset):\n",
    "    def __init__(self, data_dir, ext='png'):\n",
    "        zeros = list(glob.glob(f'{data_dir}/0/*.{ext}'))\n",
    "        ones = list(glob.glob(f'{data_dir}/1/*.{ext}'))\n",
    "        self.data = zeros + ones\n",
    "        self.labels = {}\n",
    "        for i in zeros:\n",
    "            self.labels[i.split('/')[-1]] = 0\n",
    "        for i in ones:\n",
    "            self.labels[i.split('/')[-1]] = 1\n",
    "\n",
    "        self.classes = 2\n",
    "        self.transform = transforms.Compose(\n",
    "                            [torchvision.transforms.Grayscale(num_output_channels=3),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data[idx]\n",
    "        file = os.path.basename(path)\n",
    "        img = Image.open(path)\n",
    "        label = int(self.labels[file] > 0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "zKMDnCkh0BzL",
   "metadata": {
    "id": "zKMDnCkh0BzL"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "!tar -xf ./10000LANC.tar\n",
    "# !ls\n",
    "# !rm -rf forImgClassifyCompressed/\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "748a7411",
   "metadata": {
    "id": "748a7411"
   },
   "outputs": [],
   "source": [
    "data_path = './forImgClassifyCompressed'\n",
    "# data_path = '/Users/xinye/Downloads/trailcamDataset'\n",
    "\n",
    "BATCH = 16\n",
    "\n",
    "# read whole set\n",
    "IMG_PATH = os.path.join(data_path, 'img')\n",
    "dataset = ZeroOneSet(IMG_PATH)\n",
    "\n",
    "# split train val test set\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10e7748d",
   "metadata": {
    "id": "10e7748d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v2(num_classes = 2).to(device)\n",
    "\n",
    "data_loader, data_loader_test = (trainloader, testloader)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa65eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caa65eb6",
    "outputId": "c7d690ed-9267-42c7-cca7-3a4a7fc25a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    1] loss 0.64 train_acc 68.75 train_fpr 31.25 train_fnr 0.00\n",
      "[1,  101] loss 0.81 train_acc 52.29 train_fpr 24.01 train_fnr 23.70\n",
      "[1,  201] loss 0.75 train_acc 56.69 train_fpr 21.92 train_fnr 21.39\n",
      "[1,  274] Eval_Acc 56.95 Eval_FPR 1.54 EVAL_FPR 41.12\n",
      "[2,    1] loss 0.79 train_acc 50.00 train_fpr 25.00 train_fnr 25.00\n",
      "[2,  101] loss 0.73 train_acc 62.93 train_fpr 18.44 train_fnr 18.63\n",
      "[2,  201] loss 0.68 train_acc 65.73 train_fpr 16.82 train_fnr 17.44\n",
      "[2,  274] Eval_Acc 62.98 Eval_FPR 1.54 EVAL_FPR 35.14\n",
      "[3,    1] loss 1.02 train_acc 56.25 train_fpr 6.25 train_fnr 37.50\n",
      "[3,  101] loss 0.59 train_acc 71.41 train_fpr 13.06 train_fnr 15.53\n",
      "[3,  201] loss 0.57 train_acc 72.23 train_fpr 12.78 train_fnr 14.99\n",
      "[3,  274] Eval_Acc 73.95 Eval_FPR 11.23 EVAL_FPR 14.58\n",
      "[4,    1] loss 0.33 train_acc 87.50 train_fpr 6.25 train_fnr 6.25\n",
      "[4,  101] loss 0.59 train_acc 75.80 train_fpr 11.26 train_fnr 12.93\n",
      "[4,  201] loss 0.60 train_acc 75.19 train_fpr 11.41 train_fnr 13.40\n",
      "[4,  274] Eval_Acc 78.52 Eval_FPR 6.52 EVAL_FPR 14.76\n",
      "[5,    1] loss 0.31 train_acc 81.25 train_fpr 12.50 train_fnr 6.25\n",
      "[5,  101] loss 0.60 train_acc 77.35 train_fpr 10.27 train_fnr 12.38\n",
      "[5,  201] loss 0.50 train_acc 79.85 train_fpr 9.24 train_fnr 10.91\n",
      "[5,  274] Eval_Acc 77.79 Eval_FPR 17.12 EVAL_FPR 4.89\n",
      "[6,    1] loss 0.19 train_acc 87.50 train_fpr 6.25 train_fnr 6.25\n",
      "[6,  101] loss 0.34 train_acc 85.77 train_fpr 6.62 train_fnr 7.61\n",
      "[6,  201] loss 0.36 train_acc 84.61 train_fpr 6.93 train_fnr 8.46\n",
      "[6,  274] Eval_Acc 83.00 Eval_FPR 5.34 EVAL_FPR 11.50\n",
      "[7,    1] loss 0.27 train_acc 81.25 train_fpr 18.75 train_fnr 0.00\n",
      "[7,  101] loss 0.30 train_acc 88.24 train_fpr 5.20 train_fnr 6.56\n",
      "[7,  201] loss 0.32 train_acc 86.78 train_fpr 6.13 train_fnr 7.09\n",
      "[7,  274] Eval_Acc 81.44 Eval_FPR 13.59 EVAL_FPR 4.80\n",
      "[8,    1] loss 0.31 train_acc 87.50 train_fpr 12.50 train_fnr 0.00\n",
      "[8,  101] loss 0.26 train_acc 89.05 train_fpr 5.14 train_fnr 5.82\n",
      "[8,  201] loss 0.27 train_acc 88.53 train_fpr 5.16 train_fnr 6.31\n",
      "[8,  274] Eval_Acc 80.44 Eval_FPR 3.89 EVAL_FPR 15.49\n",
      "[9,    1] loss 0.10 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[9,  101] loss 0.26 train_acc 89.98 train_fpr 4.58 train_fnr 5.45\n",
      "[9,  201] loss 0.27 train_acc 88.71 train_fpr 5.25 train_fnr 6.03\n",
      "[9,  274] Eval_Acc 84.64 Eval_FPR 4.26 EVAL_FPR 10.96\n",
      "[10,    1] loss 0.06 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[10,  101] loss 0.20 train_acc 92.20 train_fpr 3.77 train_fnr 4.02\n",
      "[10,  201] loss 0.22 train_acc 91.42 train_fpr 4.10 train_fnr 4.48\n",
      "[10,  274] Eval_Acc 83.64 Eval_FPR 10.78 EVAL_FPR 5.43\n",
      "[11,    1] loss 0.16 train_acc 93.75 train_fpr 0.00 train_fnr 6.25\n",
      "[11,  101] loss 0.19 train_acc 92.20 train_fpr 3.65 train_fnr 4.15\n",
      "[11,  201] loss 0.20 train_acc 91.95 train_fpr 3.76 train_fnr 4.29\n",
      "[11,  274] Eval_Acc 84.00 Eval_FPR 3.17 EVAL_FPR 12.68\n",
      "[12,    1] loss 0.29 train_acc 93.75 train_fpr 0.00 train_fnr 6.25\n",
      "[12,  101] loss 0.24 train_acc 90.90 train_fpr 3.96 train_fnr 5.14\n",
      "[12,  201] loss 0.26 train_acc 90.45 train_fpr 4.35 train_fnr 5.19\n",
      "[12,  274] Eval_Acc 79.80 Eval_FPR 2.54 EVAL_FPR 17.48\n",
      "[13,    1] loss 0.06 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[13,  101] loss 0.18 train_acc 93.25 train_fpr 3.28 train_fnr 3.47\n",
      "[13,  201] loss 0.18 train_acc 93.00 train_fpr 3.33 train_fnr 3.67\n",
      "[13,  274] Eval_Acc 86.01 Eval_FPR 5.80 EVAL_FPR 8.06\n",
      "[14,    1] loss 0.12 train_acc 93.75 train_fpr 6.25 train_fnr 0.00\n",
      "[14,  101] loss 0.12 train_acc 96.04 train_fpr 2.10 train_fnr 1.86\n",
      "[14,  201] loss 0.14 train_acc 95.06 train_fpr 2.24 train_fnr 2.71\n",
      "[14,  274] Eval_Acc 80.99 Eval_FPR 15.67 EVAL_FPR 3.17\n",
      "[15,    1] loss 0.01 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[15,  101] loss 0.11 train_acc 95.98 train_fpr 2.10 train_fnr 1.92\n",
      "[15,  201] loss 0.13 train_acc 95.40 train_fpr 2.27 train_fnr 2.33\n",
      "[15,  274] Eval_Acc 87.66 Eval_FPR 6.25 EVAL_FPR 5.98\n",
      "[16,    1] loss 0.03 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[16,  101] loss 0.12 train_acc 95.92 train_fpr 2.04 train_fnr 2.04\n",
      "[16,  201] loss 0.11 train_acc 95.99 train_fpr 1.96 train_fnr 2.05\n",
      "[16,  274] Eval_Acc 81.17 Eval_FPR 4.35 EVAL_FPR 14.31\n",
      "[17,    1] loss 0.08 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[17,  101] loss 0.13 train_acc 95.11 train_fpr 2.35 train_fnr 2.54\n",
      "[17,  201] loss 0.13 train_acc 94.75 train_fpr 2.52 train_fnr 2.74\n",
      "[17,  274] Eval_Acc 87.11 Eval_FPR 5.98 EVAL_FPR 6.79\n",
      "[18,    1] loss 0.06 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[18,  101] loss 0.09 train_acc 97.03 train_fpr 1.36 train_fnr 1.61\n",
      "[18,  201] loss 0.10 train_acc 96.61 train_fpr 1.52 train_fnr 1.87\n",
      "[18,  274] Eval_Acc 81.08 Eval_FPR 1.81 EVAL_FPR 16.94\n",
      "[19,    1] loss 0.07 train_acc 93.75 train_fpr 6.25 train_fnr 0.00\n",
      "[19,  101] loss 0.10 train_acc 96.72 train_fpr 1.49 train_fnr 1.79\n",
      "[19,  201] loss 0.09 train_acc 96.86 train_fpr 1.40 train_fnr 1.74\n",
      "[19,  274] Eval_Acc 83.09 Eval_FPR 2.99 EVAL_FPR 13.77\n",
      "[20,    1] loss 0.01 train_acc 100.00 train_fpr 0.00 train_fnr 0.00\n",
      "[20,  101] loss 0.10 train_acc 96.53 train_fpr 1.92 train_fnr 1.55\n",
      "[20,  201] loss 0.10 train_acc 96.52 train_fpr 1.77 train_fnr 1.71\n",
      "[20,  274] Eval_Acc 80.62 Eval_FPR 16.76 EVAL_FPR 2.45\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "'''TRAIN'''\n",
    "def train(model: nn.Module, dataloader: DataLoader):\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        running_loss = AverageMeter('loss')\n",
    "        acc = AverageMeter('train_acc')\n",
    "        fpr = AverageMeter('train_fpr')\n",
    "        fnr = AverageMeter('train_fnr')\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "\n",
    "            acc1, fn, fp = accuracy(outputs, labels)\n",
    "            fpr.update(fp)\n",
    "            fnr.update(fn)\n",
    "\n",
    "            running_loss.update(loss.item(), outputs.shape[0])\n",
    "            acc.update(acc1[0], outputs.shape[0])\n",
    "            if i % 100 == 0:    # print every 100 mini-batches\n",
    "                print('[%d, %4d]' % (epoch + 1, i + 1), running_loss, acc, fpr, fnr)\n",
    "        model.eval()\n",
    "        topEval, fprEval, fnrEval = evaluate(model, criterion, data_loader_test)\n",
    "        print('[%d, %4d]' % (epoch + 1, i + 1), topEval, fprEval, fnrEval)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "train(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03cd7d65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03cd7d65",
    "outputId": "783dfd62-60b4-45cf-d837-9cf6dc42b2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of baseline model\n",
      "Size (MB): 9.128025\n",
      "accuracy:  80.62\n",
      "FPR:  16.76\n",
      "FNR:   2.45\n"
     ]
    }
   ],
   "source": [
    "num_eval_batches = 1000\n",
    "\n",
    "print(\"Size of baseline model\")\n",
    "print_size_of_model(model)\n",
    "\n",
    "top1, fpr, fnr = evaluate(model, criterion, data_loader_test)\n",
    "print('accuracy: %6.2f' % top1.avg)\n",
    "print('FPR: %6.2f' % fpr.avg)\n",
    "print('FNR: %6.2f' % fnr.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7783b559",
   "metadata": {
    "id": "7783b559"
   },
   "outputs": [],
   "source": [
    "savePath = os.path.join(os.getcwd(), 'savedModelForTable')\n",
    "fileName = 'MobileNetV2_EuroCity.pt'\n",
    "if not os.path.exists(savePath):\n",
    "    os.mkdir(savePath)\n",
    "torch.save(model.state_dict(), os.path.join(savePath, fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fdbe1",
   "metadata": {
    "id": "8c7fdbe1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727a8d4",
   "metadata": {
    "id": "c727a8d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0079d4e",
   "metadata": {
    "id": "e0079d4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab3272",
   "metadata": {
    "id": "7eab3272"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eda798",
   "metadata": {
    "id": "92eda798"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5f6a3",
   "metadata": {
    "id": "44e5f6a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc326dc6",
   "metadata": {
    "id": "bc326dc6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d26e3",
   "metadata": {
    "id": "456d26e3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd3459",
   "metadata": {
    "id": "93dd3459"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d54948",
   "metadata": {
    "id": "c1d54948"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbbd7fc",
   "metadata": {
    "id": "adbbd7fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d46ef",
   "metadata": {
    "id": "985d46ef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a53499",
   "metadata": {
    "id": "80a53499"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99346f44",
   "metadata": {
    "id": "99346f44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386118e0",
   "metadata": {
    "id": "386118e0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcef20b",
   "metadata": {
    "id": "1fcef20b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02c18b",
   "metadata": {
    "id": "5e02c18b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db99add9",
   "metadata": {
    "id": "db99add9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7fde9",
   "metadata": {
    "id": "bba7fde9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b519eb",
   "metadata": {
    "id": "94b519eb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class TinyYOLOv5(nn.Module):\n",
    "    def __init__(self, num_classes=80):\n",
    "        super(TinyYOLOv5, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = Conv(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = Conv(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = Conv(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = Conv(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv6 = Conv(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool6 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv7 = Conv(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = Conv(1024, 256, kernel_size=1, stride=1)\n",
    "        self.conv9 = Conv(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = self.conv6(x)\n",
    "#         x = self.maxpool6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the TinyYOLOv5 model\n",
    "model = TinyYOLOv5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0a835",
   "metadata": {
    "id": "91e0a835"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the TinyYOLOv5 model and its optimizer\n",
    "model = TinyYOLOv5()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load CIFAR10 dataset for training\n",
    "train_dataset = CIFAR10(root=\"./data\", train=True, transform=ToTensor(), download=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    # Iterate over the training batches\n",
    "    for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Compute average training loss and accuracy\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(train_dataset)\n",
    "\n",
    "    # Print training metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd220cd",
   "metadata": {
    "id": "2cd220cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    ef.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    # Iterate over the training batches\n",
    "    for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = ef(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(predicted)\n",
    "#         print(labels)\n",
    "#         print()\n",
    "#         print()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Compute average training loss and accuracy\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(train_dataset)\n",
    "\n",
    "    # Print training metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72716fbf",
   "metadata": {
    "id": "72716fbf"
   },
   "outputs": [],
   "source": [
    "ef = torchvision.models.efficientnet_b0(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded6958",
   "metadata": {
    "id": "8ded6958"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eade11",
   "metadata": {
    "id": "81eade11"
   },
   "outputs": [],
   "source": [
    "model.conv10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c1e67",
   "metadata": {
    "id": "604c1e67"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ef7b2",
   "metadata": {
    "id": "4a1ef7b2"
   },
   "outputs": [],
   "source": [
    "summary(ef,(3,32,32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ff9f7",
   "metadata": {
    "id": "667ff9f7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize EfficientNet-B0 model\n",
    "model = torchvision.models.efficientnet_b0(pretrained=False, num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100. * correct / total\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    test_acc = 100. * correct / total\n",
    "    print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'\n",
    "          .format(test_loss, test_acc))\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19e446",
   "metadata": {
    "id": "ee19e446"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize EfficientNet-B0 model\n",
    "model = torchvision.models.efficientnet_b0(pretrained=False, num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100. * correct / total\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    test_acc = 100. * correct / total\n",
    "    print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'\n",
    "          .format(test_loss, test_acc))\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72449a",
   "metadata": {
    "id": "ad72449a"
   },
   "outputs": [],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07c843",
   "metadata": {
    "id": "8b07c843"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
